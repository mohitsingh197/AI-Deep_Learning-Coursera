{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "package skymind.dsx;\n\nimport com.beust.jcommander.JCommander;\nimport com.beust.jcommander.Parameter;\nimport com.beust.jcommander.ParameterException;\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.JavaSparkContext;\nimport org.datavec.api.records.reader.RecordReader;\nimport org.datavec.api.records.reader.impl.csv.CSVRecordReader;\nimport org.datavec.api.split.FileSplit;\nimport org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;\nimport org.deeplearning4j.eval.Evaluation;\nimport org.deeplearning4j.nn.modelimport.keras.KerasModelImport;\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\nimport org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer;\nimport org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster;\nimport org.nd4j.linalg.dataset.DataSet;\nimport org.nd4j.linalg.dataset.SplitTestAndTrain;\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.File;\nimport java.util.ArrayList;\nimport java.util.List;\n\n\n/**\n * Generic Keras model import runner. Takes a CSV file in a format that CSVRecordReader understands\n * and a Keras model file in HDF5.\n *\n * Example usage:\n *  $SPARK_HOME/bin/spark-submit \\\n *    --class skymind.dsx.KerasImportCSVSparkRunner \\\n *    --master $MASTER \\\n *    --files iris.txt irisModel.h5 \\\n *    dl4j.jar\n *      -batchSizePerWorker 15 \\\n *      -indexLabel 4 \\\n *      -numClasses 3 \\\n *      -modelFileName model.h5 \\\n *      -dataFileName iris.txt\n *\n *\n * @author Max Pumperla\n */\npublic class KerasImportCSVSparkRunner {\n\n    private static final Logger log = LoggerFactory.getLogger(KerasImportCSVSparkRunner.class);\n\n    @Parameter(names = \"-useSparkLocal\", description = \"Use spark local (helper for testing/running without spark submit)\", arity = 1)\n    private boolean useSparkLocal = false;\n\n    @Parameter(names = \"-loadData\", description = \"Whether to load data or not \", arity = 1)\n    private boolean loadData = true;\n\n    @Parameter(names = \"-train\", description = \"Whether to train model or not \", arity = 1)\n    private boolean train = false;\n\n    @Parameter(names = \"-batchSizePerWorker\", description = \"Number of examples to fit each worker with\")\n    private int batchSizePerWorker = 10;\n\n    @Parameter(names = \"-indexLabel\", description = \"Index of column that has labels\")\n    private int indexLabel = -1;\n\n    @Parameter(names = \"-modelFileName\", description = \"Name of the keras model file\")\n    private String modelFileName = \"model.h5\";\n\n    @Parameter(names = \"-dataFileName\", description = \"Name of the CSV file\")\n    private String dataFileName = \"data.csv\";\n\n    @Parameter(names = \"-numClasses\", description = \"Number of output classes\")\n    private int numClasses = -1;\n\n    @Parameter(names = \"-epochs\", description = \"Number of epochs to train\")\n    private int epochs = 10;\n\n    public static void main(String[] args) throws Exception {\n        new KerasImportCSVSparkRunner().entryPoint(args);\n    }\n\n    protected void entryPoint(String[] args) throws Exception {\n\n        JCommander jcmdr = new JCommander(this);\n        try {\n            jcmdr.parse(args);\n        } catch (ParameterException e) {\n            jcmdr.usage();\n            try { Thread.sleep(500); } catch (Exception e2) { }\n            throw e;\n        }\n\n        SparkConf sparkConf = new SparkConf();\n        if (useSparkLocal) {\n            sparkConf.setMaster(\"local[*]\");\n        }\n        sparkConf.setAppName(\"DL4J Keras model import runner\");\n        JavaSparkContext sc = new JavaSparkContext(sparkConf);\n\n        // Load Keras model\n        MultiLayerNetwork network = KerasModelImport.importKerasSequentialModelAndWeights(modelFileName, train);\n\n        // Build training master\n        ParameterAveragingTrainingMaster tm = new ParameterAveragingTrainingMaster.Builder(40)\n                .averagingFrequency(5)\n                .workerPrefetchNumBatches(2)\n                .batchSizePerWorker(batchSizePerWorker)\n                .build();\n\n        // Init Spark net\n        SparkDl4jMultiLayer sparkNet = new SparkDl4jMultiLayer(sc, network, tm);\n\n        if (loadData) {\n            // Assume no header and comma separation\n            int numLinesToSkip = 0;\n            char delimiter = ',';\n            RecordReader recordReader = new CSVRecordReader(numLinesToSkip, delimiter);\n            recordReader.initialize(new FileSplit(new File(dataFileName)));\n\n            DataSetIterator iterator = new RecordReaderDataSetIterator(\n                    recordReader, batchSizePerWorker, indexLabel, numClasses);\n\n            List<DataSet> dataList = new ArrayList<>();\n            while (iterator.hasNext()) {\n                dataList.add(iterator.next());\n            }\n            JavaRDD<DataSet> data = sc.parallelize(dataList);\n\n            if (train) {\n                for (int i = 0; i < epochs; i++) {\n                    sparkNet.fit(data);\n                    log.info(\"Completed Epoch {}\", i);\n                }\n            }\n\n            // Evaluation\n            Evaluation evaluation = sparkNet.evaluate(data);\n            log.info(evaluation.stats());\n            log.info(\"***** Example Complete *****\");\n        } else {\n            log.info(\"***** Model import complete\");\n        }\n    }\n}", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}