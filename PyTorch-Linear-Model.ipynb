{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "x = [i for i in range(20)]\nx_train = np.array(x, dtype=np.float32)\nprint(x_train.shape)\nx_train = x_train.reshape(-1,1)\nprint(x)\nprint(x_train.shape)\n\ny = [(5*i + 2) for i in x]\ny_train = np.array(y, dtype=np.float32)\ny_train = y_train.reshape(-1, 1)\nprint(y)\nprint(y_train.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(20,)\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n(20, 1)\n[2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92, 97]\n(20, 1)\n"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "class LinearRegressor(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LinearRegressor, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\ninput_dim = 1\noutput_dim = 1\n\nmodel = LinearRegressor(input_dim, output_dim)\n\nprint(model)\n\nloss_function = nn.MSELoss()\nprint(loss_function)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\nprint(optimizer)\n\nepochs = 500\nfor epoch in range(epochs):\n    epoch += 1\n    \n    #Convert inputs and outputs to torvh Variable\n    inputs = Variable(torch.from_numpy(x_train))\n    \n    real_outputs = Variable(torch.from_numpy(y_train))\n    \n    #Reset gradients\n    optimizer.zero_grad()\n    \n    #Forward - Compute the output\n    pred_outputs = model(inputs)\n    \n    #Loss\n    loss = loss_function(pred_outputs, real_outputs)\n    \n    #Backward - compute gradients\n    loss.backward()\n    \n    #update parameters\n    optimizer.step()\n    \n    print('epoch {} loss {}'.format(epoch, loss.data[0]))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "LinearRegressor(\n  (linear): Linear(in_features=1, out_features=1, bias=True)\n)\nMSELoss(\n)\n<torch.optim.sgd.SGD object at 0x7fb0e6059790>\nepoch 1 loss 4156.45410156\nepoch 2 loss 2347.70361328\nepoch 3 loss 1326.11206055\nepoch 4 loss 749.111633301\nepoch 5 loss 423.218444824\nepoch 6 loss 239.152297974\nepoch 7 loss 135.190551758\nepoch 8 loss 76.4723052979\nepoch 9 loss 43.3078308105\nepoch 10 loss 24.5762939453\nepoch 11 loss 13.996465683\nepoch 12 loss 8.02078437805\nepoch 13 loss 4.64557361603\nepoch 14 loss 2.7391064167\nepoch 15 loss 1.66220641136\nepoch 16 loss 1.05384731293\nepoch 17 loss 0.710124135017\nepoch 18 loss 0.515863776207\nepoch 19 loss 0.40601593256\nepoch 20 loss 0.343851536512\nepoch 21 loss 0.30862095952\nepoch 22 loss 0.288597792387\nepoch 23 loss 0.277167528868\nepoch 24 loss 0.270589470863\nepoch 25 loss 0.266752272844\nepoch 26 loss 0.264462649822\nepoch 27 loss 0.263047039509\nepoch 28 loss 0.262126386166\nepoch 29 loss 0.261485487223\nepoch 30 loss 0.261001765728\nepoch 31 loss 0.260606706142\nepoch 32 loss 0.260262429714\nepoch 33 loss 0.259947359562\nepoch 34 loss 0.259648144245\nepoch 35 loss 0.259359359741\nepoch 36 loss 0.259074091911\nepoch 37 loss 0.258793652058\nepoch 38 loss 0.258514463902\nepoch 39 loss 0.258236467838\nepoch 40 loss 0.257959187031\nepoch 41 loss 0.257683217525\nepoch 42 loss 0.257406771183\nepoch 43 loss 0.257132261992\nepoch 44 loss 0.256855517626\nepoch 45 loss 0.256581157446\nepoch 46 loss 0.256305575371\nepoch 47 loss 0.256031900644\nepoch 48 loss 0.255757391453\nepoch 49 loss 0.255484312773\nepoch 50 loss 0.255210936069\nepoch 51 loss 0.254937052727\nepoch 52 loss 0.254665315151\nepoch 53 loss 0.254392325878\nepoch 54 loss 0.254119724035\nepoch 55 loss 0.253847420216\nepoch 56 loss 0.253575533628\nepoch 57 loss 0.253305524588\nepoch 58 loss 0.253034323454\nepoch 59 loss 0.252763450146\nepoch 60 loss 0.252492725849\nepoch 61 loss 0.252222955227\nepoch 62 loss 0.251951724291\nepoch 63 loss 0.251682013273\nepoch 64 loss 0.251413106918\nepoch 65 loss 0.251144081354\nepoch 66 loss 0.250875413418\nepoch 67 loss 0.250607073307\nepoch 68 loss 0.250338435173\nepoch 69 loss 0.250070512295\nepoch 70 loss 0.249802395701\nepoch 71 loss 0.249535754323\nepoch 72 loss 0.249269366264\nepoch 73 loss 0.249001890421\nepoch 74 loss 0.248735710979\nepoch 75 loss 0.248469144106\nepoch 76 loss 0.248202413321\nepoch 77 loss 0.247937530279\nepoch 78 loss 0.247672051191\nepoch 79 loss 0.247406244278\nepoch 80 loss 0.247142627835\nepoch 81 loss 0.246877476573\nepoch 82 loss 0.246613621712\nepoch 83 loss 0.246349334717\nepoch 84 loss 0.246085315943\nepoch 85 loss 0.245821550488\nepoch 86 loss 0.245558783412\nepoch 87 loss 0.245295807719\nepoch 88 loss 0.245033338666\nepoch 89 loss 0.24477109313\nepoch 90 loss 0.244509622455\nepoch 91 loss 0.24424803257\nepoch 92 loss 0.243986651301\nepoch 93 loss 0.243725985289\nepoch 94 loss 0.243464142084\nepoch 95 loss 0.243203803897\nepoch 96 loss 0.242943644524\nepoch 97 loss 0.242684334517\nepoch 98 loss 0.242423981428\nepoch 99 loss 0.242165058851\nepoch 100 loss 0.241905361414\nepoch 101 loss 0.241646677256\nepoch 102 loss 0.241387888789\nepoch 103 loss 0.241130039096\nepoch 104 loss 0.240871354938\nepoch 105 loss 0.240612834692\nepoch 106 loss 0.240356594324\nepoch 107 loss 0.240098953247\nepoch 108 loss 0.239841490984\nepoch 109 loss 0.239585608244\nepoch 110 loss 0.239329382777\nepoch 111 loss 0.239072874188\nepoch 112 loss 0.238816529512\nepoch 113 loss 0.238561078906\nepoch 114 loss 0.238305971026\nepoch 115 loss 0.238050743937\nepoch 116 loss 0.23779591918\nepoch 117 loss 0.237541347742\nepoch 118 loss 0.237287044525\nepoch 119 loss 0.237033441663\nepoch 120 loss 0.236780256033\nepoch 121 loss 0.236525505781\nepoch 122 loss 0.23627281189\nepoch 123 loss 0.236020177603\nepoch 124 loss 0.235768288374\nepoch 125 loss 0.235515236855\nepoch 126 loss 0.235263258219\nepoch 127 loss 0.235010623932\nepoch 128 loss 0.23475985229\nepoch 129 loss 0.234507828951\nepoch 130 loss 0.23425757885\nepoch 131 loss 0.234006047249\nepoch 132 loss 0.233756303787\nepoch 133 loss 0.233505964279\nepoch 134 loss 0.233256906271\nepoch 135 loss 0.233006760478\nepoch 136 loss 0.232757210732\nepoch 137 loss 0.232507824898\nepoch 138 loss 0.232260033488\nepoch 139 loss 0.232011288404\nepoch 140 loss 0.231762602925\nepoch 141 loss 0.231514379382\nepoch 142 loss 0.231266662478\nepoch 143 loss 0.23101913929\nepoch 144 loss 0.230771929026\nepoch 145 loss 0.230524927378\nepoch 146 loss 0.230278089643\nepoch 147 loss 0.230031684041\nepoch 148 loss 0.229785963893\nepoch 149 loss 0.229538962245\nepoch 150 loss 0.229293972254\nepoch 151 loss 0.22904856503\nepoch 152 loss 0.228803798556\nepoch 153 loss 0.228557825089\nepoch 154 loss 0.228313848376\nepoch 155 loss 0.228070139885\nepoch 156 loss 0.227825328708\nepoch 157 loss 0.227582097054\nepoch 158 loss 0.227337390184\nepoch 159 loss 0.227094978094\nepoch 160 loss 0.226851314306\nepoch 161 loss 0.226609185338\nepoch 162 loss 0.226365849376\nepoch 163 loss 0.226123124361\nepoch 164 loss 0.225882574916\nepoch 165 loss 0.225640103221\nepoch 166 loss 0.225398659706\nepoch 167 loss 0.225156933069\nepoch 168 loss 0.224915593863\nepoch 169 loss 0.224676415324\nepoch 170 loss 0.224435761571\nepoch 171 loss 0.224195569754\nepoch 172 loss 0.223955482244\nepoch 173 loss 0.223715901375\nepoch 174 loss 0.223476245999\nepoch 175 loss 0.223237544298\nepoch 176 loss 0.222997277975\nepoch 177 loss 0.222758725286\nepoch 178 loss 0.222520440817\nepoch 179 loss 0.222282379866\nepoch 180 loss 0.222045108676\nepoch 181 loss 0.221806332469\nepoch 182 loss 0.22156958282\nepoch 183 loss 0.221332788467\nepoch 184 loss 0.221095234156\nepoch 185 loss 0.220858722925\nepoch 186 loss 0.220621824265\nepoch 187 loss 0.220386475325\nepoch 188 loss 0.220149710774\nepoch 189 loss 0.219914823771\nepoch 190 loss 0.219678997993\nepoch 191 loss 0.219444841146\nepoch 192 loss 0.219209507108\nepoch 193 loss 0.218974515796\nepoch 194 loss 0.218741387129\nepoch 195 loss 0.218506649137\nepoch 196 loss 0.218272686005\nepoch 197 loss 0.218038827181\nepoch 198 loss 0.217805147171\nepoch 199 loss 0.217571809888\nepoch 200 loss 0.217340350151\nepoch 201 loss 0.217107698321\nepoch 202 loss 0.216875404119\nepoch 203 loss 0.216643244028\nepoch 204 loss 0.216410040855\nepoch 205 loss 0.216178372502\nepoch 206 loss 0.215946957469\nepoch 207 loss 0.215716764331\nepoch 208 loss 0.215485453606\nepoch 209 loss 0.215255662799\nepoch 210 loss 0.21502391994\nepoch 211 loss 0.214794784784\nepoch 212 loss 0.214564532042\nepoch 213 loss 0.214334324002\nepoch 214 loss 0.214105680585\nepoch 215 loss 0.21387720108\nepoch 216 loss 0.213647603989\nepoch 217 loss 0.213419437408\nepoch 218 loss 0.213190436363\nepoch 219 loss 0.21296222508\nepoch 220 loss 0.212734058499\nepoch 221 loss 0.212506145239\nepoch 222 loss 0.212280005217\nepoch 223 loss 0.212051838636\nepoch 224 loss 0.211824983358\nepoch 225 loss 0.211597725749\nepoch 226 loss 0.211372703314\nepoch 227 loss 0.211145445704\nepoch 228 loss 0.210919424891\nepoch 229 loss 0.210693925619\nepoch 230 loss 0.210468441248\nepoch 231 loss 0.210243180394\nepoch 232 loss 0.210018128157\nepoch 233 loss 0.209793373942\nepoch 234 loss 0.209568932652\nepoch 235 loss 0.209344416857\nepoch 236 loss 0.209120467305\nepoch 237 loss 0.208897203207\nepoch 238 loss 0.208672255278\nepoch 239 loss 0.208449691534\nepoch 240 loss 0.208226487041\nepoch 241 loss 0.208004355431\nepoch 242 loss 0.207780554891\nepoch 243 loss 0.207558706403\nepoch 244 loss 0.207337230444\nepoch 245 loss 0.207114726305\nepoch 246 loss 0.206893712282\nepoch 247 loss 0.206671908498\nepoch 248 loss 0.206451147795\nepoch 249 loss 0.206229403615\nepoch 250 loss 0.206008076668\nepoch 251 loss 0.205788463354\nepoch 252 loss 0.205567866564\nepoch 253 loss 0.205347210169\nepoch 254 loss 0.205128714442\nepoch 255 loss 0.204908490181\nepoch 256 loss 0.204689234495\nepoch 257 loss 0.204469844699\nepoch 258 loss 0.204250976443\nepoch 259 loss 0.204033613205\nepoch 260 loss 0.203814774752\nepoch 261 loss 0.203596681356\nepoch 262 loss 0.203378751874\nepoch 263 loss 0.203161090612\nepoch 264 loss 0.202943608165\nepoch 265 loss 0.202726721764\nepoch 266 loss 0.20250852406\nepoch 267 loss 0.202291965485\nepoch 268 loss 0.202076166868\nepoch 269 loss 0.201859325171\nepoch 270 loss 0.201644018292\nepoch 271 loss 0.201427429914\nepoch 272 loss 0.201212316751\nepoch 273 loss 0.200997322798\nepoch 274 loss 0.200781181455\nepoch 275 loss 0.200566574931\nepoch 276 loss 0.200351387262\nepoch 277 loss 0.2001375705\nepoch 278 loss 0.199923291802\nepoch 279 loss 0.199709266424\nepoch 280 loss 0.199495017529\nepoch 281 loss 0.199282363057\nepoch 282 loss 0.199069276452\nepoch 283 loss 0.198855429888\nepoch 284 loss 0.198643058538\nepoch 285 loss 0.198430597782\nepoch 286 loss 0.198217660189\nepoch 287 loss 0.198005318642\nepoch 288 loss 0.197794571519\nepoch 289 loss 0.197582229972\nepoch 290 loss 0.197370871902\nepoch 291 loss 0.197159349918\nepoch 292 loss 0.196948558092\nepoch 293 loss 0.196737825871\nepoch 294 loss 0.196527272463\nepoch 295 loss 0.196316808462\nepoch 296 loss 0.196106895804\nepoch 297 loss 0.195897236466\nepoch 298 loss 0.195687785745\nepoch 299 loss 0.195477366447\nepoch 300 loss 0.195268884301\nepoch 301 loss 0.195059895515\nepoch 302 loss 0.194851621985\nepoch 303 loss 0.19464187324\nepoch 304 loss 0.194433987141\nepoch 305 loss 0.194226592779\nepoch 306 loss 0.194017916918\nepoch 307 loss 0.193810775876\nepoch 308 loss 0.19360281527\nepoch 309 loss 0.193396121264\nepoch 310 loss 0.193188503385\nepoch 311 loss 0.192982211709\nepoch 312 loss 0.192775249481\nepoch 313 loss 0.192568451166\nepoch 314 loss 0.192362934351\nepoch 315 loss 0.192157000303\nepoch 316 loss 0.191950902343\nepoch 317 loss 0.191746518016\nepoch 318 loss 0.191540956497\nepoch 319 loss 0.191335648298\nepoch 320 loss 0.191131219268\nepoch 321 loss 0.190926387906\nepoch 322 loss 0.190721899271\nepoch 323 loss 0.190517693758\nepoch 324 loss 0.190313771367\nepoch 325 loss 0.190110161901\nepoch 326 loss 0.189906746149\nepoch 327 loss 0.189703792334\nepoch 328 loss 0.18950073421\nepoch 329 loss 0.189297914505\nepoch 330 loss 0.189095720649\nepoch 331 loss 0.188893511891\nepoch 332 loss 0.188690438867\nepoch 333 loss 0.188489079475\nepoch 334 loss 0.188287764788\nepoch 335 loss 0.188084930182\nepoch 336 loss 0.187884524465\nepoch 337 loss 0.187683552504\nepoch 338 loss 0.187482371926\nepoch 339 loss 0.187281683087\nepoch 340 loss 0.187080934644\nepoch 341 loss 0.186880990863\nepoch 342 loss 0.186681002378\nepoch 343 loss 0.186481639743\nepoch 344 loss 0.186281830072\nepoch 345 loss 0.186081618071\nepoch 346 loss 0.185883253813\nepoch 347 loss 0.185684114695\nepoch 348 loss 0.185485109687\nepoch 349 loss 0.185287371278\nepoch 350 loss 0.185088738799\nepoch 351 loss 0.184890374541\nepoch 352 loss 0.184692800045\nepoch 353 loss 0.184494763613\nepoch 354 loss 0.184297114611\nepoch 355 loss 0.184099748731\nepoch 356 loss 0.183902829885\nepoch 357 loss 0.183706074953\nepoch 358 loss 0.183509200811\nepoch 359 loss 0.183313399553\nepoch 360 loss 0.183117344975\nepoch 361 loss 0.182921081781\nepoch 362 loss 0.182725429535\nepoch 363 loss 0.182530611753\nepoch 364 loss 0.182334139943\nepoch 365 loss 0.182139530778\nepoch 366 loss 0.181944638491\nepoch 367 loss 0.181749150157\nepoch 368 loss 0.18155542016\nepoch 369 loss 0.181361347437\nepoch 370 loss 0.181166723371\nepoch 371 loss 0.180973023176\nepoch 372 loss 0.180778831244\nepoch 373 loss 0.180585831404\nepoch 374 loss 0.18039226532\nepoch 375 loss 0.180200010538\nepoch 376 loss 0.18000665307\nepoch 377 loss 0.17981351912\nepoch 378 loss 0.179621621966\nepoch 379 loss 0.179429262877\nepoch 380 loss 0.179236501455\nepoch 381 loss 0.179045781493\nepoch 382 loss 0.178853347898\nepoch 383 loss 0.178662195802\nepoch 384 loss 0.178471013904\nepoch 385 loss 0.178279474378\nepoch 386 loss 0.178088724613\nepoch 387 loss 0.177898749709\nepoch 388 loss 0.177708804607\nepoch 389 loss 0.177518680692\nepoch 390 loss 0.177328035235\nepoch 391 loss 0.177137583494\nepoch 392 loss 0.17694824934\nepoch 393 loss 0.176759108901\nepoch 394 loss 0.176570281386\nepoch 395 loss 0.176381081343\nepoch 396 loss 0.176192730665\nepoch 397 loss 0.176003336906\nepoch 398 loss 0.175815492868\nepoch 399 loss 0.175627425313\nepoch 400 loss 0.175439417362\nepoch 401 loss 0.175251275301\nepoch 402 loss 0.175064057112\nepoch 403 loss 0.174876078963\nepoch 404 loss 0.174689203501\nepoch 405 loss 0.1745018363\nepoch 406 loss 0.174315497279\nepoch 407 loss 0.174128681421\nepoch 408 loss 0.173942863941\nepoch 409 loss 0.173756450415\nepoch 410 loss 0.173570543528\nepoch 411 loss 0.173384979367\nepoch 412 loss 0.17319945991\nepoch 413 loss 0.173013344407\nepoch 414 loss 0.172829061747\nepoch 415 loss 0.172643661499\nepoch 416 loss 0.172459080815\nepoch 417 loss 0.172274276614\nepoch 418 loss 0.172089472413\nepoch 419 loss 0.171905115247\nepoch 420 loss 0.171722128987\nepoch 421 loss 0.171538501978\nepoch 422 loss 0.171354860067\nepoch 423 loss 0.171170786023\nepoch 424 loss 0.170987352729\nepoch 425 loss 0.170804619789\nepoch 426 loss 0.170622184873\nepoch 427 loss 0.170439615846\nepoch 428 loss 0.1702568084\nepoch 429 loss 0.170075327158\nepoch 430 loss 0.169892311096\nepoch 431 loss 0.169710829854\nepoch 432 loss 0.169529139996\nepoch 433 loss 0.16934838891\nepoch 434 loss 0.169166475534\nepoch 435 loss 0.168985515833\nepoch 436 loss 0.168803974986\nepoch 437 loss 0.168624043465\nepoch 438 loss 0.168443590403\nepoch 439 loss 0.168263211846\nepoch 440 loss 0.168082639575\nepoch 441 loss 0.167903006077\nepoch 442 loss 0.167723149061\nepoch 443 loss 0.167544528842\nepoch 444 loss 0.167364731431\nepoch 445 loss 0.167185172439\nepoch 446 loss 0.16700732708\nepoch 447 loss 0.16682818532\nepoch 448 loss 0.166649535298\nepoch 449 loss 0.166470497847\nepoch 450 loss 0.166292384267\nepoch 451 loss 0.166115313768\nepoch 452 loss 0.165937513113\nepoch 453 loss 0.165759474039\nepoch 454 loss 0.165582329035\nepoch 455 loss 0.165405124426\nepoch 456 loss 0.165228024125\nepoch 457 loss 0.165051043034\nepoch 458 loss 0.164874464273\nepoch 459 loss 0.164698392153\nepoch 460 loss 0.164522141218\nepoch 461 loss 0.164344802499\nepoch 462 loss 0.164169475436\nepoch 463 loss 0.163993880153\nepoch 464 loss 0.163818717003\nepoch 465 loss 0.163642600179\nepoch 466 loss 0.163467735052\nepoch 467 loss 0.163293167949\nepoch 468 loss 0.163118332624\nepoch 469 loss 0.162943810225\nepoch 470 loss 0.162769705057\nepoch 471 loss 0.162594974041\nepoch 472 loss 0.162420853972\nepoch 473 loss 0.162246778607\nepoch 474 loss 0.162073999643\nepoch 475 loss 0.161899968982\nepoch 476 loss 0.161727204919\nepoch 477 loss 0.161553606391\nepoch 478 loss 0.161380365491\nepoch 479 loss 0.161208599806\nepoch 480 loss 0.161035522819\nepoch 481 loss 0.160862907767\nepoch 482 loss 0.160690233111\nepoch 483 loss 0.160519480705\nepoch 484 loss 0.160347267985\nepoch 485 loss 0.160175412893\nepoch 486 loss 0.160004094243\nepoch 487 loss 0.159832984209\nepoch 488 loss 0.159661605954\nepoch 489 loss 0.159490793943\nepoch 490 loss 0.15932007134\nepoch 491 loss 0.159149587154\nepoch 492 loss 0.158979639411\nepoch 493 loss 0.158809140325\nepoch 494 loss 0.158639192581\nepoch 495 loss 0.158469408751\nepoch 496 loss 0.158300429583\nepoch 497 loss 0.158129885793\nepoch 498 loss 0.157961159945\nepoch 499 loss 0.157791912556\nepoch 500 loss 0.157623484731\n"
                }
            ], 
            "execution_count": 7
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}