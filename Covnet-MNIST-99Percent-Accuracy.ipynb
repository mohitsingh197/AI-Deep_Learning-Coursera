{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "'''Trains a simple convnet on the MNIST dataset.\n\nGets to 99.25% test accuracy after 12 epochs\n(there is still a lot of margin for parameter tuning).\n16 seconds per epoch on a GRID K520 GPU.\n'''\n\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11280384/11490434 [============================>.] - ETA: 0sx_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "\n\n#Please construct the following neural network and report accuracy after training\n#Layer 1: 2D Convolution with 32 hidden neurons, kernel 3 by 3, relu activation (Note: input_shape is given)\n#Layer 2: 2D Convolution with 64 hidden neurons, kernel 3 by 3, relu activation \n#Layer 3: 2D MaxPooling, pool_size 2 by 2\n#Layer 4: 25% Dropout\n#Layer 5: Flatten (Hint: model.add(Flatten()))\n#Layer 6: Fully connected layer with 128 neurons, relu activation\n#Layer 7: 50% Dropout\n#Layer 8 Softmax Output Layer according to the problem (output vector)\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n#your_code_goes_here\n\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\n#some learners constantly reported 502 errors in Watson Studio. \n#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.\n#This is a workaround to limit resource consumption\n\nfrom keras import backend as K\n\n#K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/12\n60000/60000 [==============================] - 356s - loss: 7.6447 - acc: 0.5226 - val_loss: 4.5412 - val_acc: 0.7152\nEpoch 2/12\n60000/60000 [==============================] - 361s - loss: 5.7870 - acc: 0.6385 - val_loss: 4.0097 - val_acc: 0.7496\nEpoch 3/12\n60000/60000 [==============================] - 360s - loss: 5.3362 - acc: 0.6663 - val_loss: 3.5144 - val_acc: 0.7791\nEpoch 4/12\n60000/60000 [==============================] - 356s - loss: 4.8313 - acc: 0.6974 - val_loss: 3.0909 - val_acc: 0.8065\nEpoch 5/12\n60000/60000 [==============================] - 360s - loss: 4.6027 - acc: 0.7121 - val_loss: 2.9034 - val_acc: 0.8184\nEpoch 6/12\n60000/60000 [==============================] - 370s - loss: 4.3628 - acc: 0.7270 - val_loss: 2.6271 - val_acc: 0.8355\nEpoch 7/12\n60000/60000 [==============================] - 359s - loss: 4.4527 - acc: 0.7216 - val_loss: 2.6517 - val_acc: 0.8340\nEpoch 8/12\n60000/60000 [==============================] - 357s - loss: 4.3262 - acc: 0.7297 - val_loss: 2.4447 - val_acc: 0.8469\nEpoch 9/12\n60000/60000 [==============================] - 354s - loss: 4.1588 - acc: 0.7401 - val_loss: 2.4467 - val_acc: 0.8470\nEpoch 10/12\n60000/60000 [==============================] - 358s - loss: 4.1516 - acc: 0.7410 - val_loss: 2.3406 - val_acc: 0.8537\nEpoch 11/12\n60000/60000 [==============================] - 357s - loss: 4.0906 - acc: 0.7450 - val_loss: 2.9442 - val_acc: 0.8168\nEpoch 12/12\n60000/60000 [==============================] - 358s - loss: 3.9830 - acc: 0.7517 - val_loss: 2.9028 - val_acc: 0.8193\nTest loss: 2.90275719023\nTest accuracy: 0.8193\n"
                }
            ], 
            "execution_count": 5
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}