{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "import numpy as np\nimport pandas as pd\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nimport keras, math\nfrom  sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nimport pickle\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom queue import Queue\n%matplotlib inline", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "data_healthy = pickle.load(open('watsoniotp.healthy.pickle', 'rb'))\ndata_broken = pickle.load(open('watsoniotp.broken.pickle', 'rb'))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "'ascii' codec can't decode byte 0xa4 in position 0: ordinal not in range(128)", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-2-53ab770ff34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_healthy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watsoniotp.healthy.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_broken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watsoniotp.broken.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xa4 in position 0: ordinal not in range(128)"
                    ], 
                    "ename": "UnicodeDecodeError"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "data_healthy = pd.read_pickle('watsoniotp.healthy.pickle')\ndata_broken =pd.read_pickle('watsoniotp.broken.pickle')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "print (data_healthy.shape)\nprint (data_broken.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(3000, 3)\n(3000, 3)\n"
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "data_healthy = data_healthy.reshape(3000,3)\ndata_broken = data_broken.reshape(3000,3)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 9
        }, 
        {
            "source": "def scaleData(data):\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(data)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 10
        }, 
        {
            "source": "data_healthy_scaled = scaleData(data_healthy)\ndata_broken_scaled = scaleData(data_broken)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "timesteps = 10\ndim = 3\nsamples = 300\ndata_healthy_scaled_reshaped = data_healthy_scaled", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 12
        }, 
        {
            "source": "# design network\n\nmodel = Sequential()\nmodel.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=False))\nmodel.add(Dense(timesteps*dim))\nmodel.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.95, decay=5e-4, nesterov=True))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 13
        }, 
        {
            "source": "from systemml.mllearn import Keras2DML", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "inconsistent use of tabs and spaces in indentation (estimators.py, line 922)", 
                    "traceback": [
                        "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n", 
                        "  File \u001b[1;32m\"/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n", 
                        "  File \u001b[1;32m\"<ipython-input-18-5a1bd6f82cc9>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from systemml.mllearn import Keras2DML\n", 
                        "\u001b[0;36m  File \u001b[0;32m\"/gpfs/fs01/user/s613-ce8dfc36d194a2-56b67737d6cd/.local/lib/python3.5/site-packages/systemml/mllearn/__init__.py\"\u001b[0;36m, line \u001b[0;32m45\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .estimators import *\u001b[0m\n", 
                        "\u001b[0;36m  File \u001b[0;32m\"/gpfs/fs01/user/s613-ce8dfc36d194a2-56b67737d6cd/.local/lib/python3.5/site-packages/systemml/mllearn/estimators.py\"\u001b[0;36m, line \u001b[0;32m922\u001b[0m\n\u001b[0;31m    keras_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.95, decay=5e-4, nesterov=True))\u001b[0m\n\u001b[0m                                                                                                                                           ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
                    ], 
                    "ename": "TabError"
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "## Now use Keras2DML importer", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nepochs = 50\nbatch_size = 50\nmax_iter = int(epochs*math.ceil(samples/batch_size))\nmodel = Keras2DML(spark, model, input_shape=(timesteps, dim, 1), batch_size=batch_size, max_iter=max_iter, test_interval=0, display=10)\nmodel.set(perform_one_hot_encoding=False)\nmodel.set(debug=True)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "inconsistent use of tabs and spaces in indentation (estimators.py, line 922)", 
                    "traceback": [
                        "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n", 
                        "  File \u001b[1;32m\"/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n", 
                        "  File \u001b[1;32m\"<ipython-input-17-da3ea927cf74>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from systemml.mllearn import Keras2DML\n", 
                        "\u001b[0;36m  File \u001b[0;32m\"/gpfs/fs01/user/s613-ce8dfc36d194a2-56b67737d6cd/.local/lib/python3.5/site-packages/systemml/mllearn/__init__.py\"\u001b[0;36m, line \u001b[0;32m45\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .estimators import *\u001b[0m\n", 
                        "\u001b[0;36m  File \u001b[0;32m\"/gpfs/fs01/user/s613-ce8dfc36d194a2-56b67737d6cd/.local/lib/python3.5/site-packages/systemml/mllearn/estimators.py\"\u001b[0;36m, line \u001b[0;32m922\u001b[0m\n\u001b[0;31m    keras_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.95, decay=5e-4, nesterov=True))\u001b[0m\n\u001b[0m                                                                                                                                           ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
                    ], 
                    "ename": "TabError"
                }
            ], 
            "execution_count": 17
        }, 
        {
            "source": "def train(data):\n    data = data.reshape(samples, timesteps*dim)\n    model.fit(data, data) # epochs=50, batch_size=72, validation_data=(data, data), verbose=0, shuffle=False,callbacks=[LossHistory()])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "train(data_healthy_scaled)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}