{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "!ls", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\trklib.py\r\niris.txt\t\t\t\t\t\trklib.pyc\r\nmodel.h5\t\t\t\t\t\tscratch_space\r\nmodel.h5.base64\r\n"
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "!wget https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2018-04-19 00:00:51--  https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nResolving github.com (github.com)... 192.30.253.113, 192.30.253.112\nConnecting to github.com (github.com)|192.30.253.113|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180419%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180419T050051Z&X-Amz-Expires=300&X-Amz-Signature=cb25cd7340e103645a36d6388826b70f61f2546907678317c58ec2c1fce7aa33&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream [following]\n--2018-04-19 00:00:51--  https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180419%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180419T050051Z&X-Amz-Expires=300&X-Amz-Signature=cb25cd7340e103645a36d6388826b70f61f2546907678317c58ec2c1fce7aa33&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream\nResolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.97.123\nConnecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.97.123|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 445763450 (425M) [application/octet-stream]\nSaving to: \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019\n\n100%[======================================>] 445,763,450 8.43MB/s   in 53s    \n\n2018-04-19 00:01:45 (8.08 MB/s) - \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019 saved [445763450/445763450]\n\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "!wget https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2018-04-19 00:01:45--  https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2850 (2.8K) [text/plain]\nSaving to: \u2018iris.txt\u2019\n\n100%[======================================>] 2,850       --.-K/s   in 0s      \n\n2018-04-19 00:01:45 (26.6 MB/s) - \u2018iris.txt\u2019 saved [2850/2850]\n\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "!java -version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "java version \"1.8.0\"\r\nJava(TM) SE Runtime Environment (build pxa6480sr2fp10ifix-20160125_01(SR2 FP10+IV80623))\r\nIBM J9 VM (build 2.8, JRE 1.8.0 Linux amd64-64 Compressed References 20160125_287487 (JIT enabled, AOT enabled)\r\nJ9VM - R28_20160125_0846_B287487\r\nJIT  - tr.r14.java_20151209_107110.03\r\nGC   - R28_20160125_0846_B287487_CMPRSS\r\nJ9CL - 20160125_287487)\r\nJCL - 20151231_01 based on Oracle jdk8u71-b15\r\n"
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "!java -cp dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar skymind.dsx.IrisClassifier", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n185 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dnsns.jar\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/traceformat.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmldsigprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/CmpCrmf.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/nashorn.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlencprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmpkcs11impl.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjcefips.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfj-interface.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/IBMSecureRandom.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/localedata.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfj.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/xmlencfw.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jverbs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/cldrdata.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmsaslprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfjview.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/zipfs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlcrypto.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmcmsprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmkeycert.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/healthcenter.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/gskikm.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjceprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jaccess.jar\n1267 [main] INFO org.reflections.Reflections  - Reflections took 1077 ms to scan 26 urls, producing 130092 keys and 143785 values \n2095 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n2097 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n2450 [main] INFO org.reflections.Reflections  - Reflections took 352 ms to scan 1 urls, producing 31 keys and 227 values \n3259 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n3262 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n3262 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [0.5GB];\n3262 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [MKL]\n3283 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n3964 [main] INFO org.reflections.Reflections  - Reflections took 680 ms to scan 1 urls, producing 421 keys and 1666 values \n4143 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n4450 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n21773 [main] INFO org.reflections.Reflections  - Reflections took 17323 ms to scan 1 urls, producing 6280 keys and 43014 values \n21835 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21835 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21835 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n21835 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n21835 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21839 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21839 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21840 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n21840 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n21840 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n21866 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n21987 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.445355798585908\n26362 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3117849239501134\n29063 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.13503842085504067\n30752 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.09373453793773703\n31886 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.07677946941452482\n34186 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.06787442041218482\n36666 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.06256920698203443\n37824 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.05911256845950561\n39291 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.05669135732259778\n40831 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.054889760640395475\n42337 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 23 times\nExamples labeled as 1 classified by model as 1: 13 times\nExamples labeled as 2 classified by model as 2: 17 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        1.0000\n Precision:       1.0000\n Recall:          1.0000\n F1 Score:        1.0000\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "!$SPARK_HOME/bin/spark-submit \\\n--class skymind.dsx.IrisClassifier \\\n--master $MASTER \\\n--files iris.txt \\\ndl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v23/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v23/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n18/04/19 00:12:47 INFO linalg.factory.Nd4jBackend: Loaded [CpuBackend] backend\n0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n18/04/19 00:12:48 WARN org.reflections.Reflections: could not create Dir using jarFile from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar. skipping.\njava.lang.NullPointerException\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:223)\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:165)\n\tat java.util.jar.JarFile.<init>(JarFile.java:179)\n\tat java.util.jar.JarFile.<init>(JarFile.java:143)\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$1.createDir(Vfs.java:212)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:99)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n1279 [main] WARN org.reflections.Reflections  - could not create Dir using jarFile from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar. skipping.\njava.lang.NullPointerException\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:223)\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:165)\n\tat java.util.jar.JarFile.<init>(JarFile.java:179)\n\tat java.util.jar.JarFile.<init>(JarFile.java:143)\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$1.createDir(Vfs.java:212)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:99)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n18/04/19 00:12:48 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: Could not open url connection\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:37)\n\tat org.reflections.vfs.JarInputDir$1.iterator(JarInputDir.java:33)\n\tat org.reflections.Reflections.scan(Reflections.java:240)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.io.FileNotFoundException: /gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar (No such file or directory)\n\tat java.io.FileInputStream.open(FileInputStream.java:212)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:152)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:104)\n\tat sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:103)\n\tat sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:201)\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:36)\n\t... 28 more\n1285 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: Could not open url connection\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:37)\n\tat org.reflections.vfs.JarInputDir$1.iterator(JarInputDir.java:33)\n\tat org.reflections.Reflections.scan(Reflections.java:240)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.io.FileNotFoundException: /gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar (No such file or directory)\n\tat java.io.FileInputStream.open(FileInputStream.java:212)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:152)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:104)\n\tat sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:103)\n\tat sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:201)\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:36)\n\t... 28 more\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:48 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1328 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:48 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1330 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2124 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2125 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2336 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2337 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2512 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2513 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2514 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2515 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2724 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2727 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2828 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:12:49 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2829 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:12:50 INFO org.reflections.Reflections: Reflections took 2899 ms to scan 473 urls, producing 262391 keys and 350709 values \n2952 [main] INFO org.reflections.Reflections  - Reflections took 2899 ms to scan 473 urls, producing 262391 keys and 350709 values \n18/04/19 00:12:50 INFO nd4j.nativeblas.NativeOpsHolder: Number of threads used for NativeOps: 12\n3517 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n18/04/19 00:12:50 INFO org.reflections.Reflections: Reflections took 405 ms to scan 1 urls, producing 31 keys and 227 values \n3926 [main] INFO org.reflections.Reflections  - Reflections took 405 ms to scan 1 urls, producing 31 keys and 227 values \n18/04/19 00:12:51 INFO nd4j.nativeblas.Nd4jBlas: Number of threads used for BLAS: 12\n4237 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n18/04/19 00:12:51 INFO ops.executioner.DefaultOpExecutioner: Backend used: [CPU]; OS: [Linux]\n4239 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n18/04/19 00:12:51 INFO ops.executioner.DefaultOpExecutioner: Cores: [48]; Memory: [1.5GB];\n4240 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [1.5GB];\n18/04/19 00:12:51 INFO ops.executioner.DefaultOpExecutioner: Blas vendor: [MKL]\n4240 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [MKL]\n18/04/19 00:12:51 INFO org.reflections.Reflections: Reflections took 491 ms to scan 1 urls, producing 421 keys and 1666 values \n4763 [main] INFO org.reflections.Reflections  - Reflections took 491 ms to scan 1 urls, producing 421 keys and 1666 values \n18/04/19 00:12:51 INFO skymind.dsx.IrisClassifier: Build model....\n4855 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n18/04/19 00:13:00 WARN org.reflections.Reflections: could not create Dir using jarFile from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar. skipping.\njava.lang.NullPointerException\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:223)\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:165)\n\tat java.util.jar.JarFile.<init>(JarFile.java:179)\n\tat java.util.jar.JarFile.<init>(JarFile.java:143)\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$1.createDir(Vfs.java:212)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:99)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n13402 [main] WARN org.reflections.Reflections  - could not create Dir using jarFile from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar. skipping.\njava.lang.NullPointerException\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:223)\n\tat java.util.zip.ZipFile.<init>(ZipFile.java:165)\n\tat java.util.jar.JarFile.<init>(JarFile.java:179)\n\tat java.util.jar.JarFile.<init>(JarFile.java:143)\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$1.createDir(Vfs.java:212)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:99)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n18/04/19 00:13:00 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: Could not open url connection\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:37)\n\tat org.reflections.vfs.JarInputDir$1.iterator(JarInputDir.java:33)\n\tat org.reflections.Reflections.scan(Reflections.java:240)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.io.FileNotFoundException: /gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar (No such file or directory)\n\tat java.io.FileInputStream.open(FileInputStream.java:212)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:152)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:104)\n\tat sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:103)\n\tat sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:201)\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:36)\n\t... 20 more\n13403 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: Could not open url connection\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:37)\n\tat org.reflections.vfs.JarInputDir$1.iterator(JarInputDir.java:33)\n\tat org.reflections.Reflections.scan(Reflections.java:240)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.io.FileNotFoundException: /gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/*.jar (No such file or directory)\n\tat java.io.FileInputStream.open(FileInputStream.java:212)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:152)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:104)\n\tat sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:103)\n\tat sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:201)\n\tat org.reflections.vfs.JarInputDir$1$1.<init>(JarInputDir.java:36)\n\t... 20 more\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:00 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n13680 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:00 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n13681 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:09 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n22106 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:09 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n22107 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:13 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n26064 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:13 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n26065 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:16 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n29591 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:16 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n29591 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:16 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n29592 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:16 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n29592 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:18 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n31060 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:18 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n31061 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:18 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n31841 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/04/19 00:13:18 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n31841 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s613-ce8dfc36d194a2-56b67737d6cd/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/04/19 00:13:20 INFO org.reflections.Reflections: Reflections took 28389 ms to scan 448 urls, producing 18069 keys and 119810 values \n33660 [main] INFO org.reflections.Reflections  - Reflections took 28389 ms to scan 448 urls, producing 18069 keys and 119810 values \n18/04/19 00:13:20 INFO nn.multilayer.MultiLayerNetwork: Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n33805 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n18/04/19 00:13:21 INFO optimize.listeners.ScoreIterationListener: Score at iteration 0 is 1.4503432203098932\n33979 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4503432203098932\n18/04/19 00:13:23 INFO optimize.listeners.ScoreIterationListener: Score at iteration 100 is 0.3764868197219004\n36145 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3764868197219004\n18/04/19 00:13:24 INFO optimize.listeners.ScoreIterationListener: Score at iteration 200 is 0.1550995659390031\n37844 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.1550995659390031\n18/04/19 00:13:25 INFO optimize.listeners.ScoreIterationListener: Score at iteration 300 is 0.08993599428745176\n38798 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.08993599428745176\n18/04/19 00:13:26 INFO optimize.listeners.ScoreIterationListener: Score at iteration 400 is 0.06407071474583585\n39886 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.06407071474583585\n18/04/19 00:13:28 INFO optimize.listeners.ScoreIterationListener: Score at iteration 500 is 0.04992620290639443\n41043 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.04992620290639443\n18/04/19 00:13:29 INFO optimize.listeners.ScoreIterationListener: Score at iteration 600 is 0.040889703084018784\n42096 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.040889703084018784\n18/04/19 00:13:30 INFO optimize.listeners.ScoreIterationListener: Score at iteration 700 is 0.03453616749717467\n43138 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.03453616749717467\n18/04/19 00:13:31 INFO optimize.listeners.ScoreIterationListener: Score at iteration 800 is 0.02977896763874561\n44013 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.02977896763874561\n18/04/19 00:13:31 INFO optimize.listeners.ScoreIterationListener: Score at iteration 900 is 0.026060830116422223\n44554 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.026060830116422223\n18/04/19 00:13:33 INFO skymind.dsx.IrisClassifier: \nExamples labeled as 0 classified by model as 0: 17 times\nExamples labeled as 1 classified by model as 1: 21 times\nExamples labeled as 1 classified by model as 2: 1 times\nExamples labeled as 2 classified by model as 2: 14 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9811\n Precision:       0.9778\n Recall:          0.9848\n F1 Score:        0.9808\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n46038 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 17 times\nExamples labeled as 1 classified by model as 1: 21 times\nExamples labeled as 1 classified by model as 2: 1 times\nExamples labeled as 2 classified by model as 2: 14 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9811\n Precision:       0.9778\n Recall:          0.9848\n F1 Score:        0.9808\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 11
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}