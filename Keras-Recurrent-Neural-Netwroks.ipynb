{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "from keras.layers.recurrent import LSTM\nfrom keras.layers.embeddings import Embedding", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "LSTM(units,\n    activation='tanh',\n    recurrent_activation='hard_sigmoid',\n    recurrent_initializer='orthogonal',\n    recurrent_regularizer=None,\n    dropout=0.0, recurrent_dropout=0.0,\n    return_sequences=False)\n\n\n\nEmbedding(input_dim, # Vocabulary size\n         output_dim, # Output Vector length\n         embeddings_initializer='uniform',\n         mask_zero=False #mask zero values\n         )\n\n          ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Example Movie Review Sentimental Analysis\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding\nfrom keras.datasets import imdb\n\nmax_features = 20000\nmaxlen = 80\n\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\nmodel.fit(x_train, y_train, batch_size=32, epochs=15, validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, batch_size=32)\n\nprint(\"\\nLoss: \")\nprint(score[0])\nprint(\"Accuracy: \")\nprint(score[1])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/15\n25000/25000 [==============================] - 197s - loss: 0.6931 - acc: 0.5054 - val_loss: 0.6930 - val_acc: 0.5156\nEpoch 2/15\n25000/25000 [==============================] - 214s - loss: 0.6929 - acc: 0.5138 - val_loss: 0.6927 - val_acc: 0.5314\nEpoch 3/15\n25000/25000 [==============================] - 209s - loss: 0.6927 - acc: 0.5213 - val_loss: 0.6925 - val_acc: 0.5336\nEpoch 4/15\n25000/25000 [==============================] - 209s - loss: 0.6924 - acc: 0.5242 - val_loss: 0.6923 - val_acc: 0.5479\nEpoch 5/15\n25000/25000 [==============================] - 204s - loss: 0.6921 - acc: 0.5306 - val_loss: 0.6922 - val_acc: 0.5020\nEpoch 6/15\n25000/25000 [==============================] - 203s - loss: 0.6919 - acc: 0.5455 - val_loss: 0.6918 - val_acc: 0.5704\nEpoch 7/15\n25000/25000 [==============================] - 203s - loss: 0.6915 - acc: 0.5600 - val_loss: 0.6915 - val_acc: 0.5562\nEpoch 8/15\n25000/25000 [==============================] - 202s - loss: 0.6911 - acc: 0.5450 - val_loss: 0.6911 - val_acc: 0.5526\nEpoch 9/15\n25000/25000 [==============================] - 208s - loss: 0.6908 - acc: 0.5562 - val_loss: 0.6906 - val_acc: 0.5834\nEpoch 10/15\n25000/25000 [==============================] - 220s - loss: 0.6902 - acc: 0.5691 - val_loss: 0.6902 - val_acc: 0.5506\nEpoch 11/15\n25000/25000 [==============================] - 218s - loss: 0.6896 - acc: 0.5786 - val_loss: 0.6895 - val_acc: 0.5708\nEpoch 12/15\n25000/25000 [==============================] - 192s - loss: 0.6888 - acc: 0.5782 - val_loss: 0.6887 - val_acc: 0.5595\nEpoch 13/15\n25000/25000 [==============================] - 212s - loss: 0.6877 - acc: 0.5890 - val_loss: 0.6875 - val_acc: 0.5938\nEpoch 14/15\n25000/25000 [==============================] - 194s - loss: 0.6864 - acc: 0.5968 - val_loss: 0.6860 - val_acc: 0.5970\nEpoch 15/15\n25000/25000 [==============================] - 208s - loss: 0.6842 - acc: 0.6020 - val_loss: 0.6834 - val_acc: 0.6054\n25000/25000 [==============================] - 48s    \n\nLoss: \n0.683408661938\nAccuracy: \n0.6054\n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}